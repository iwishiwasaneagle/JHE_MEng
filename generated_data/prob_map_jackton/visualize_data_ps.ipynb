{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['OPP4SAR_DIR'] = '/home/jhewers/Documents/meng_project/code/'\n",
    "sys.path.insert(0,os.getenv('OPP4SAR_DIR'))\n",
    "DIR = os.path.join(os.getenv('OPP4SAR_DIR'),'generated_data/prob_map_jackton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({\n",
    "    'axes.grid':False,\n",
    "    'figure.dpi':300,\n",
    "    'image.cmap':'gray',\n",
    "    'legend.loc':'upper left',\n",
    "    'legend.fancybox':True,\n",
    "    })\n",
    "def legend_decorator(method):\n",
    "    def decorate_legend(*args,**kwargs):\n",
    "        cust_kwargs = {'bbox_to_anchor':(1.05, 1)}\n",
    "        cust_kwargs.update(kwargs)\n",
    "        return method(*args,**cust_kwargs)\n",
    "    return decorate_legend\n",
    "plt.legend = legend_decorator(plt.legend)\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import scipy as sp\n",
    "import os\n",
    "import csv\n",
    "from PIL import ImageColor, Image\n",
    "\n",
    "import utm\n",
    "\n",
    "from src.json_helpers import GlobalJsonDecoder\n",
    "from src.data_models.positional.waypoint import Waypoint, Waypoints\n",
    "from src.data_models.probability_map import ProbabilityMap\n",
    "from src.waypoint_generation import WaypointFactory, WaypointAlgSettings\n",
    "from src.enums import WaypointAlgorithmEnum\n",
    "from src.simulation.vehicle import VehicleSimData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math\n",
    "MERCATOR_RANGE = 256\n",
    "\n",
    "def  bound(value, opt_min, opt_max):\n",
    "  if (opt_min != None): \n",
    "    value = max(value, opt_min)\n",
    "  if (opt_max != None): \n",
    "    value = min(value, opt_max)\n",
    "  return value\n",
    "\n",
    "def  degreesToRadians(deg) :\n",
    "  return deg * (math.pi / 180)\n",
    "\n",
    "def  radiansToDegrees(rad) :\n",
    "  return rad / (math.pi / 180)\n",
    "\n",
    "class G_Point:\n",
    "    def __init__(self,x=0, y=0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "class G_LatLng:\n",
    "    def __init__(self,lt, ln):\n",
    "        self.lat = lt\n",
    "        self.lng = ln\n",
    "\n",
    "class MercatorProjection:\n",
    "    def __init__(self) :\n",
    "      self.pixelOrigin_ =  G_Point( MERCATOR_RANGE / 2, MERCATOR_RANGE / 2)\n",
    "      self.pixelsPerLonDegree_ = MERCATOR_RANGE / 360\n",
    "      self.pixelsPerLonRadian_ = MERCATOR_RANGE / (2 * math.pi)\n",
    "\n",
    "    def fromLatLngToPoint(self, latLng, opt_point=None) :\n",
    "      point = opt_point if opt_point is not None else G_Point(0,0)\n",
    "      origin = self.pixelOrigin_\n",
    "      point.x = origin.x + latLng.lng * self.pixelsPerLonDegree_\n",
    "      # NOTE(appleton): Truncating to 0.9999 effectively limits latitude to\n",
    "      # 89.189.  This is about a third of a tile past the edge of the world tile.\n",
    "      siny = bound(math.sin(degreesToRadians(latLng.lat)), -0.9999, 0.9999)\n",
    "      point.y = origin.y + 0.5 * math.log((1 + siny) / (1 - siny)) * -     self.pixelsPerLonRadian_\n",
    "      return point\n",
    "\n",
    "    def fromPointToLatLng(self,point) :\n",
    "          origin = self.pixelOrigin_\n",
    "          lng = (point.x - origin.x) / self.pixelsPerLonDegree_\n",
    "          latRadians = (point.y - origin.y) / -self.pixelsPerLonRadian_\n",
    "          lat = radiansToDegrees(2 * math.atan(math.exp(latRadians)) - math.pi / 2)\n",
    "          return G_LatLng(lat, lng)\n",
    "    \n",
    "    #pixelCoordinate = worldCoordinate * pow(2,zoomLevel)\n",
    "    \n",
    "def getCorners(center, zoom, mapWidth, mapHeight):\n",
    "    scale = 2**zoom\n",
    "    proj = MercatorProjection()\n",
    "    centerPx = proj.fromLatLngToPoint(center)\n",
    "    SWPoint = G_Point(centerPx.x-(mapWidth/2)/scale, centerPx.y+(mapHeight/2)/scale)\n",
    "    SWLatLon = proj.fromPointToLatLng(SWPoint)\n",
    "    NEPoint = G_Point(centerPx.x+(mapWidth/2)/scale, centerPx.y-(mapHeight/2)/scale)\n",
    "    NELatLon = proj.fromPointToLatLng(NEPoint)\n",
    "    return {\n",
    "        'N' : NELatLon.lat,\n",
    "        'E' : NELatLon.lng,\n",
    "        'S' : SWLatLon.lat,\n",
    "        'W' : SWLatLon.lng,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.waypoint_generation import CostFunc\n",
    "cost_func = CostFunc()\n",
    "\n",
    "wp_gen_settings = WaypointAlgSettings.Global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR,\"output_sar_ps.json\"),'r') as f:\n",
    "    data_sar = json.load(f,cls=GlobalJsonDecoder)\n",
    "    print(type(data_sar))\n",
    "with open(os.path.join(DIR,\"output_sim_ps.json\"), 'r') as f:\n",
    "    data_sim = json.load(f,cls=GlobalJsonDecoder)\n",
    "    print(type(data_sim))\n",
    "with open(os.path.join(DIR,\"output_wp_ps.json\"), 'r') as f:\n",
    "    data_wp = json.load(f,cls=GlobalJsonDecoder)\n",
    "    print(type(data_wp))\n",
    "\n",
    "R = 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AirDataUAV as ADU \n",
    "from PIL import Image\n",
    "\n",
    "d1 = ADU.UAVData(\"/home/jhewers/Documents/meng_project/ps_data/2020-11-19_14-18-29.csv\")\n",
    "d2 = ADU.UAVData(\"/home/jhewers/Documents/meng_project/ps_data/2020-11-19_14-39-52.csv\")\n",
    "d3 = ADU.UAVData(\"/home/jhewers/Documents/meng_project/ps_data/2020-11-19_15-16-33.csv\")\n",
    "\n",
    "img = ProbabilityMap.fromPNG(\"/home/jhewers/Documents/meng_project/code/img/probability_imgs/prob_map_8_jackton.png\")\n",
    "img_location = ProbabilityMap.fromPNG(\"/home/jhewers/Documents/meng_project/code/img/probability_imgs/prob_map_8_jackton_map.png\")\n",
    "\n",
    "center = G_LatLng(55.751849, -4.238594)\n",
    "corners = getCorners(center, 17, 1280/2,1280/2)\n",
    "N,W,_,_ = utm.from_latlon(corners['N'],corners['W'])\n",
    "S,E,_,_ = utm.from_latlon(corners['S'],corners['E'])\n",
    "\n",
    "w_m,h_m = (W-E,S-N)\n",
    "ORIGIN = np.array([N,W])\n",
    "\n",
    "img = img.resampled(int(h_m),int(w_m))\n",
    "img_location = img_location.resampled(int(h_m),int(w_m))\n",
    "\n",
    "for d in [d1,d2,d3]:\n",
    "    d.utm[0] -= ORIGIN[0]\n",
    "    d.utm[1] = -(d.utm[1] - ORIGIN[1])\n",
    "\n",
    "plt.imshow(img_location.toIMG())\n",
    "plt.imshow(img.toIMG(),alpha = 0.4)\n",
    "\n",
    "for dat in data_sim.data:\n",
    "    x = dat[1].pos.x\n",
    "    y = [f for f in dat[1].pos.y]\n",
    "    plt.plot(x,y,label=str(dat[0]).split('.')[1].lower())\n",
    "    plt.scatter(x[0],y[0])\n",
    "\n",
    "plt.plot(d1.utm[0],d1.utm[1],label=\"PS ASU Inspector\")\n",
    "plt.scatter(d1.utm[0][0],d1.utm[1][0])\n",
    "plt.plot(d2.utm[0],d2.utm[1],label=\"PS AUS Steven Preece\")\n",
    "plt.scatter(d2.utm[0][0],d2.utm[1][0])\n",
    "plt.plot(d3.utm[0],d3.utm[1],label='Attempted Parallel Swaths')\n",
    "plt.scatter(d3.utm[0][0],d3.utm[1][0])\n",
    "plt.ylabel(\"y (m)\")\n",
    "plt.xlabel(\"x (m)\")\n",
    "plt.legend()\n",
    "fig=plt.gcf()\n",
    "fig.savefig(os.path.join(DIR,'paths_ps.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 25\n",
    "for d,label in zip([d1,d2,d3],[\"PS ASU Inspector\",\"PS AUS Steven Preece\",\"Attempted Parallel Swaths\"]):\n",
    "    file_path = os.path.join(DIR,f\"prob_accum_w_t_{'_'.join(label.split())}.csv\")\n",
    "    t_arr= []\n",
    "    c_arr = []\n",
    "    if os.path.isfile(file_path):\n",
    "        print(f\"File {file_path} found\")\n",
    "        with open(file_path,'r') as f:\n",
    "            csvreader = csv.DictReader(f) \n",
    "            for row in csvreader:\n",
    "                c_arr.append(float(row['cost']))\n",
    "                t_arr.append(float(row['time']))\n",
    "    else:\n",
    "        print(f\"File {file_path} NOT found\")\n",
    "        wp_arr = []\n",
    "        x = d.utm[0]\n",
    "        y = d.utm[1]\n",
    "        print(f\"{label} - {npts} points to calculate...\")\n",
    "        for i in range(0,len(x),len(x)//npts):\n",
    "            xi = x[i]\n",
    "            yi = y[i]\n",
    "            ti = d.t_s[i]\n",
    "            wp_arr.append(Waypoint(xi,yi))\n",
    "            wps = Waypoints(wp_arr)\n",
    "            cost = cost_func.calculate(wps,img,R)\n",
    "            t_arr.append(ti)\n",
    "            c_arr.append(cost)    \n",
    "            print(f\"{label}: {i}/{len(x)}\")        \n",
    "        with open(file_path,'w') as f:\n",
    "            csvwriter = csv.writer(f)\n",
    "            csvwriter.writerow(['time','cost'])\n",
    "            csvwriter.writerows([(f,g) for f,g in zip(t_arr,c_arr)])\n",
    "    \n",
    "    plt.plot(t_arr,c_arr, label=label)\n",
    "    print(f\"Final cost for {label} is {c_arr[-1]:.4f}\")\n",
    "\n",
    "alg,vehicle = data_sim.data[0]\n",
    "file_path = os.path.join(DIR,f\"prob_accum_w_t_{str(alg).split('.')[1].lower()}.csv\")\n",
    "t_arr= []\n",
    "c_arr = []\n",
    "if os.path.isfile(file_path):\n",
    "    print(f\"File {file_path} found\")\n",
    "    with open(file_path,'r') as f:\n",
    "        csvreader = csv.DictReader(f) \n",
    "        for row in csvreader:\n",
    "            c_arr.append(float(row['cost']))\n",
    "            t_arr.append(float(row['time']))\n",
    "else:\n",
    "    wp_arr = []\n",
    "    x = np.array(vehicle.pos.x)\n",
    "    y = np.array(vehicle.pos.y)\n",
    "    t = vehicle.t\n",
    "    print(f\"{alg} - {npts} points to calculate...\")\n",
    "    for i in range(0,len(x),len(x)//npts) :\n",
    "        xi = x[i]\n",
    "        yi = y[i]\n",
    "        ti = t[i]\n",
    "        wp_arr.append(Waypoint(xi,yi))\n",
    "        wps = Waypoints(wp_arr)\n",
    "        cost = cost_func.calculate(wps,img,R)\n",
    "        t_arr.append(ti)\n",
    "        c_arr.append(cost)    \n",
    "        print(f\"{alg} data: {i}/{len(x)}\")\n",
    "    with open(file_path,'w') as f:\n",
    "            csvwriter = csv.writer(f)\n",
    "            csvwriter.writerow(['time','cost'])\n",
    "            csvwriter.writerows([(f,g) for f,g in zip(t_arr,c_arr)])\n",
    "print(f\"Final cost for {alg} is {c_arr[-1]:.4f}\")\n",
    "plt.plot(t_arr,c_arr, label=str(alg).split('.')[1])\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Accumulated probability\")\n",
    "plt.ylim([0, -1])\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.savefig(os.path.join(DIR,\"accumulated_probability_ps.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PLOT SIMULATION\n",
    "cutoff = 20*60\n",
    "\n",
    "def plot(alg,d,img):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    wps = d.pos\n",
    "    t = np.array(d.t)\n",
    "    wps_x = np.array(wps.x)\n",
    "    wps_y = np.array(wps.y)\n",
    "    \n",
    "    ax.plot(wps_x[np.where(t>=cutoff)],wps_y[np.where(t>=cutoff)],linewidth=3,label='Over 20mins')\n",
    "    below = ax.plot(wps_x[np.where(t<cutoff)],wps_y[np.where(t<cutoff)],linewidth=3,label='Below 20mins')\n",
    "    ax.scatter(wps_x[0],wps_y[0],50,color=below[0].get_color(),label=f'Start',zorder=100)\n",
    "\n",
    "\n",
    "    ax.set_xlabel(\"x (m)\")\n",
    "    ax.set_ylabel(\"y (m)\")\n",
    "\n",
    "    mn,mx = ax.get_xlim()\n",
    "    ax.set_xlim([mn-20,mx+20])\n",
    "    mn,mx = ax.get_ylim()\n",
    "    ax.set_ylim([mn+20,mx-20])\n",
    "    \n",
    "    s = str(alg).split('.')[1]\n",
    "    fig.savefig(os.path.join(DIR,s+\"_sim.png\"))\n",
    "    ax.set_title(s)\n",
    "       \n",
    "    return fig,ax\n",
    "\n",
    "for key in data_sim.data:\n",
    "    alg, output = key\n",
    "    fig,ax = plot(alg,output,img)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SAR SIM for PS data\n",
    "import diskcache as dc\n",
    "import tempfile\n",
    "\n",
    "objs = np.array(data_sar.data)\n",
    "\n",
    "for d,label in zip([d1,d2,d3],[\"PS ASU Inspector\",\"PS AUS Steven Preece\",\"Attempted Parallel Swaths\"]):\n",
    "    wps = data_wp.data[str(alg)]['wps']\n",
    "    \n",
    "    print(label)\n",
    "    vehicle = VehicleSimData()\n",
    "    cache = dc.Cache(os.path.join(tempfile.gettempdir(),'opp4sar',str(np.random.rand())[2:]))\n",
    "    \n",
    "    max_x,max_y = np.max(objs,axis=0)\n",
    "    min_x,min_y = np.min(objs,axis=0)\n",
    "    x,y = np.meshgrid(np.arange(min_x,max_x+1),np.arange(min_y,max_y+1))\n",
    "    x,y=x.flatten(),y.flatten()\n",
    "    objs_possible_xy = np.vstack((x,y)).T\n",
    "\n",
    "    for xi,yi,ti in zip(d.utm[0],d.utm[1],d.t_s):\n",
    "        # create distance vectors\n",
    "        v = np.array([xi-objs_possible_xy[:,0],\n",
    "                    yi-objs_possible_xy[:, 1]])\n",
    "\n",
    "        # if distance is < search radius -> object found\n",
    "        dist = np.linalg.norm(v, axis=0)\n",
    "\n",
    "        if any(dist < R):\n",
    "            inds = np.where(dist < R)[0]\n",
    "            for ind in inds:\n",
    "                loc = objs_possible_xy[ind]\n",
    "                cache[f'{loc[0]},{loc[1]}'] = ti                            \n",
    "            objs_possible_xy = np.delete(objs_possible_xy, inds, axis=0)\n",
    "\n",
    "    for key in cache.iterkeys():\n",
    "        t = cache[key]\n",
    "        xy=tuple(np.array(key.split(',')).astype(float).astype(int))\n",
    "        inds = np.where((objs[:,0]==xy[0])&(objs[:,1]==xy[1]))[0]\n",
    "        for ind in inds:\n",
    "            vehicle.found.append(\n",
    "                (t,objs[ind])\n",
    "            )\n",
    "\n",
    "    data_sim.data.append((label,vehicle))\n",
    "    del vehicle, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_objects = len(data_sar.data)\n",
    "colors = np.array([ImageColor.getcolor(f, \"RGB\") for f in \n",
    "         ['#b71c1c',\n",
    "          '#311b92',\n",
    "          '#ff6f00', \n",
    "          '#4fc3f7',\n",
    "          '#d500f9',\n",
    "          '#1b5e20']])/255\n",
    "\n",
    "t_hists = {}\n",
    "for alg,vehicle in data_sim.data:\n",
    "    v_found = np.array(vehicle.found)[:,0]\n",
    "    if alg in t_hists:\n",
    "        t_hists[alg] = np.append(t_hists[alg],v_found)\n",
    "    else:\n",
    "        t_hists[alg] = v_found\n",
    "\n",
    "dct = {}\n",
    "cutoff = 20*60\n",
    "\n",
    "for i,(alg,t_hist) in enumerate(t_hists.items()):\n",
    "\n",
    "    t_hist = t_hist.astype(float)\n",
    "    t_hist = t_hist[np.where(t_hist<cutoff+5*60)]\n",
    "    print(f\"{alg}: {100*len(t_hist)/total_objects:.2f}% found ({len(t_hist)} out of {total_objects})\")\n",
    "    mean = np.mean(t_hist)\n",
    "    \n",
    "    if '.' in (alg:=str(alg)):\n",
    "        alg = alg.split('.')[1].lower()\n",
    "\n",
    "    dct[str(alg)] = {\n",
    "        'color':colors[i],\n",
    "        't_hist_s':t_hist,\n",
    "        't_hist_min':t_hist/60,\n",
    "        'mean':np.mean(t_hist),\n",
    "        'before_endurance_limit':np.sum(t_hist<cutoff)/total_objects\n",
    "        }\n",
    "    print(f\"{alg} w/ mean time to found = {mean:.2f}s and found before endurance limit ({cutoff}s) = {100*np.sum(t_hist<cutoff)/total_objects:.2f}%\")\n",
    "\n",
    "values = [f['t_hist_min'] for f in dct.values()]\n",
    "plt.hist(values,bins = 10,label=dct.keys())\n",
    "\n",
    "plt.ylabel(\"Found count at time\")\n",
    "plt.xlabel(\"Time till object found (minutes)\")\n",
    "\n",
    "plt.axvspan(20,30,edgecolor='w',facecolor='r',alpha=0.3,zorder=-100,label='Over endurance',hatch='///')\n",
    "\n",
    "\n",
    "plt.xlim([0,np.max([np.max(f) for f in values])])\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(DIR,\"time_till_object_found_ps.png\"))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(x,y,x_label,y_label):\n",
    "\n",
    "    fig,ax = plt.subplots(constrained_layout=True)\n",
    "    plt.xticks(rotation=45)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.grid(True, linestyle='--', which='major',\n",
    "                       color='grey', alpha=.25)\n",
    "    rects = ax.bar(x,y)   \n",
    "\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "    max_y = np.max(y)\n",
    "    ax.set_ylim([0, int(np.ceil(max_y / 100.0)) * 110])\n",
    "    \n",
    "    return fig,ax\n",
    "\n",
    "plot_bar([f for f in dct],[100*dct[f]['before_endurance_limit'] for f in dct],'','% found within endurance limit')\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(DIR,\"found_within_endurance.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max = -np.inf\n",
    "for alg,d in dct.items():\n",
    "    t_hist = d['t_hist_s']\n",
    "    y = []\n",
    "    x = []\n",
    "    if max(t_hist)>x_max:x_max = max(t_hist)\n",
    "    for i in np.linspace(0,max(t_hist)):\n",
    "        x.append(i)\n",
    "        y.append(100*np.sum(t_hist<i)/total_objects)\n",
    "\n",
    "    plt.plot(x,y,label=f\"{alg}\",color=d['color'])\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([0,x_max])\n",
    "plt.ylabel(\"Percentage found (%)\")\n",
    "plt.xlabel(\"Endurance limited time-to-find (s)\")\n",
    "fig = plt.gcf()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(DIR,\"endurance_limited_time-to-find_ps.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meng_project",
   "name": "meng_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
